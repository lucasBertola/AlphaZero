{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM0tiPEeU8r3km/ZDqgOPNJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucasBertola/AlphaZero/blob/main/Play_again_alpha_zero.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To load the model faster, it is recommended to activate the GPU in Google Colab. To do this, follow these steps:\n",
        "\n",
        "1. Click on `Runtime` or `Execution` in the top menu.\n",
        "2. Select `Change runtime type` from the dropdown menu.\n",
        "3. In the `Hardware accelerator` section, choose `GPU` from the dropdown menu.\n",
        "4. Click `Save` to apply the changes.\n",
        "\n",
        "After activating the GPU, the model should load and run faster."
      ],
      "metadata": {
        "id": "y4sAPrZF4hGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone  https://github.com/lucasBertola/AlphaZero.git\n",
        "!pip install -r AlphaZero/requirement.txt\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import io\n",
        "import sys\n",
        "import random\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "from IPython.display import display, HTML\n",
        "os.chdir(\"AlphaZero\") if os.path.isdir(\"AlphaZero\") else None\n",
        "\n",
        "from connect_four_gymnasium import ConnectFourEnv\n",
        "from connect_four_gymnasium.players import ConsolePlayer\n",
        "from alphaFour import AlphaFour\n",
        "import base64\n",
        "\n",
        "class MCTSPlayer:\n",
        "    def __init__(self, ai: AlphaFour, name=\"MCTS\", deterministic=True):\n",
        "        self.ai = ai\n",
        "        self.name = name\n",
        "        self.deterministic = deterministic\n",
        "\n",
        "    def play_single(self, observation):\n",
        "        env = ConnectFourEnv()\n",
        "        env.reset()\n",
        "        env.board = observation\n",
        "        predicted_policies, _ = self.ai.mcts_parallel([env])\n",
        "        return np.argmax(predicted_policies, axis=1)\n",
        "\n",
        "    def play(self, observations):\n",
        "        if isinstance(observations, list):\n",
        "            envs = [ConnectFourEnv() for _ in range(len(observations))]\n",
        "            for i, env in enumerate(envs):\n",
        "                env.reset()\n",
        "                env.board = observations[i]\n",
        "            predicted_policies, values = self.ai.mcts_parallel(envs)\n",
        "        else:\n",
        "            env = ConnectFourEnv()\n",
        "            env.reset()\n",
        "            env.board = observations\n",
        "            predicted_policies, values = self.ai.mcts_parallel([env])\n",
        "\n",
        "        print(f'IA: I think I have a {round(((values[0][0] + 1) / 2) * 100)}% chance of winning')\n",
        "        return np.argmax(predicted_policies, axis=1)\n",
        "\n",
        "    def getName(self):\n",
        "        return self.name\n",
        "\n",
        "    def is_deterministic(self):\n",
        "        return self.deterministic\n",
        "\n",
        "    def get_elo(self):\n",
        "        return None\n",
        "\n",
        "\n",
        "def find_latest_model():\n",
        "    for i in reversed(range(500)):\n",
        "        path = f'models/model_{i}.pt'\n",
        "        if os.path.exists(path):\n",
        "            return path, i\n",
        "\n",
        "    return None, None\n",
        "\n",
        "\n",
        "def display_rgb_array(rgb_array):\n",
        "    img = Image.fromarray(rgb_array, 'RGB')\n",
        "    img.show()\n",
        "\n",
        "def display_centered_image(rgb_array):\n",
        "    img = Image.fromarray(rgb_array, 'RGB')\n",
        "    img_data = io.BytesIO()\n",
        "    img.save(img_data, format='PNG')\n",
        "    img_data = img_data.getvalue()\n",
        "    img_width, img_height = img.size\n",
        "    display(HTML(f'<div style=\"display: flex; justify-content: center;\"><img src=\"data:image/png;base64,{base64.b64encode(img_data).decode()}\" width=\"{img_width}\" height=\"{img_height}\" /></div>'))\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    latest_model_path, generation = find_latest_model()\n",
        "\n",
        "    if latest_model_path is not None:\n",
        "        print(f'Loading model generation {generation}')\n",
        "        ai_instance = AlphaFour(latest_model_path,iteration=2500)\n",
        "    else:\n",
        "        print('Error: No model found')\n",
        "        exit()\n",
        "\n",
        "    mcts_player = MCTSPlayer(ai_instance, 'MCTS')\n",
        "    human_player = ConsolePlayer()\n",
        "    env = ConnectFourEnv(render_mode=\"rgb_array\",main_player_name=\"You\")\n",
        "\n",
        "    observation, _ = env.reset()\n",
        "    display_centered_image(env.render())\n",
        "\n",
        "    players = [human_player, mcts_player]\n",
        "    random.shuffle(players)\n",
        "\n",
        "    for _ in range(5000):\n",
        "        for player in players:\n",
        "            action = player.play(observation)\n",
        "            observation, rewards, done, truncated, _ = env.step(action)\n",
        "            display_centered_image(env.render())\n",
        "            if truncated or done:\n",
        "                print('finish')\n",
        "                return\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "uG53TQOkrLiL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}